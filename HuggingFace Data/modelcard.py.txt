Configuration base class and utilities.

    Structured Model Card class. Store model card as well as methods for loading/downloading/saving model cards.

    Please read the following paper for details and explanation on the sections: "Model Cards for Model Reporting" by
    Margaret Mitchell, Simone Wu, Andrew Zaldivar, Parker Barnes, Lucy Vasserman, Ben Hutchinson, Elena Spitzer,
    Inioluwa Deborah Raji and Timnit Gebru for the proposal behind model cards. Link: https://arxiv.org/abs/1810.03993

    Note: A model card can be loaded and saved to disk.
    
Save a model card object to the directory or file `save_directory_or_file`.

        Instantiate a [`ModelCard`] from a pre-trained model model card.

        Parameters:
            pretrained_model_name_or_path: either:

                - a string, the *model id* of a pretrained model card hosted inside a model repo on huggingface.co.
                - a path to a *directory* containing a model card file saved using the [`~ModelCard.save_pretrained`]
                  method, e.g.: `./my_model_directory/`.
                - a path or url to a saved model card JSON *file*, e.g.: `./my_model_directory/modelcard.json`.

            cache_dir: (*optional*) string:
                Path to a directory in which a downloaded pre-trained model card should be cached if the standard cache
                should not be used.

            kwargs: (*optional*) dict: key/value pairs with which to update the ModelCard object after loading.

                - The values in kwargs of any keys which are model card attributes will be used to override the loaded
                  values.
                - Behavior concerning key/value pairs whose keys are *not* model card attributes is controlled by the
                  *return_unused_kwargs* keyword parameter.

            proxies: (*optional*) dict, default None:
                A dictionary of proxy servers to use by protocol or endpoint, e.g.: {'http': 'foo.bar:3128',
                'http://hostname': 'foo.bar:4012'}. The proxies are used on each request.

            return_unused_kwargs: (*optional*) bool:

                - If False, then this function returns just the final model card object.
                - If True, then this functions returns a tuple *(model card, unused_kwargs)* where *unused_kwargs* is a
                  dictionary consisting of the key/value pairs whose keys are not model card attributes: ie the part of
                  kwargs which has not been used to update *ModelCard* and is otherwise ignored.

        Examples:

        ```python
        # Download model card from huggingface.co and cache.
        modelcard = ModelCard.from_pretrained("google-bert/bert-base-uncased")
        # Model card was saved using *save_pretrained('./test/saved_model/')*
        modelcard = ModelCard.from_pretrained("./test/saved_model/")
        modelcard = ModelCard.from_pretrained("./test/saved_model/modelcard.json")
        modelcard = ModelCard.from_pretrained("google-bert/bert-base-uncased", output_attentions=True, foo=False)
        ```
Constructs a `ModelCard` from a Python dictionary of parameters.
Constructs a `ModelCard` from a json file of parameters.
Serializes this instance to a Python dictionary.
Serializes this instance to a JSON string.
Save this instance to a json file.

<!-- This model card has been generated automatically according to the information the Trainer had access to. You
should probably proofread and complete it, then remove this comment. -->


<!-- This model card has been generated automatically according to the information Keras had access to. You should
probably proofread and complete it, then remove this comment. -->


    Parse the `logs` of either a `keras.History` object returned by `model.fit()` or an accumulated logs `dict`
    passed to the `PushToHubCallback`. Returns lines and logs compatible with those returned by `parse_log_history`.
    

    Parse the `log_history` of a Trainer to get the intermediate and final evaluation results.
    

    Create a nice Markdown table from the results in `lines`.
    
# coding=utf-8
# Copyright 2018 The HuggingFace Inc. team.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
# Recommended attributes from https://arxiv.org/abs/1810.03993 (see papers)
# Open additional attributes
# If we save using the predefined names, we can load using `from_pretrained`
# Download model card from huggingface.co and cache.
# Model card was saved using *save_pretrained('./test/saved_model/')*
# Load from URL or cache if already cached
# Load model card
# We fall back on creating an empty model card
# Update model card with kwargs if needed
# Infer default license from the checkpoint used, if possible.
# Dataset mapping tag -> name
# One entry per dataset and per task
# Remove partial results to avoid the model card being rejected.
# Now the model card for realsies.
# {self.model_name}\n\n"
## Model description\n\nMore information needed\n"
## Intended uses & limitations\n\nMore information needed\n"
## Training and evaluation data\n\nMore information needed\n"
## Training procedure\n"
### Training hyperparameters\n"
### Training results\n\n"
### Framework versions\n\n"
# Infer default from dataset
# Those are not real datasets from the Hub so we exclude them.
# Infer default finetuned_from
# Infer default task tag:
# Add `generated_from_trainer` to the tags
# Infer default from dataset
# Those are not real datasets from the Hub so we exclude them.
# Infer default finetuned_from
# Infer default task tag:
# Add `generated_from_keras_callback` to the tags
# This looks like a `History` object
# This history looks empty, return empty results
# Training logs is a list of dicts, let's invert it to a dict of lists to match a History object
# If there are no training logs
# From now one we can assume we have training logs: